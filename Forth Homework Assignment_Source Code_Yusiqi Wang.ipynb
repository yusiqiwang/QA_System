{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import sklearn as skl\n",
    "import itertools\n",
    "import ast\n",
    "import datetime\n",
    "import nltk\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import csv\n",
    "import operator\n",
    "import warnings\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pandas import *\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from elasticsearch import helpers\n",
    "from elasticsearch.helpers import bulk\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./all_articles.txt','r',encoding='utf-8',errors='ignore') as txt:\n",
    "    corpus = ast.literal_eval(txt.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ergodic the txt\n",
    "corpus = list(itertools.chain(*corpus))\n",
    "corpus = list(itertools.chain(*corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Earlier today we had a strong South Korean PMI report.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the ergodic result\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish the Elasticsearch\n",
    "es_articles = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the article to Elasticsearch,Sentence by sentence\n",
    "document = []\n",
    "for i in range(len(corpus)):\n",
    "    sentences = corpus[i]\n",
    "    documents = {\n",
    "        \"_index\" : \"articles_all\",\n",
    "        \"_type\" : \"article_type\",\n",
    "        \"_id\" : i,\n",
    "        \"_source\" :{\n",
    "            \"any\" : \"data\" + str(i),\n",
    "            \"timestamp\" : datetime.now(),\n",
    "            \"body\" : sentences\n",
    "        }\n",
    "    }\n",
    "    document.append(documents)\n",
    "if len(document) > 0:\n",
    "    helpers.bulk(es_articles , document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raise Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raise entities \n",
    "#Use the nltk.word_tokenize ,pos_tag and ne_chunk to raise entities\n",
    "def rais_entities(sent):\n",
    "    if type(sent) == str:\n",
    "        nerEntities = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)))\n",
    "    else:\n",
    "        nerEntities = nltk.ne_chunk(nltk.pos_tag(sent))\n",
    "    result = []\n",
    "    current = []\n",
    "    #Accord NerEntities to decide the nerEntities's Object\n",
    "    #If nerEntities is Tree put the keywords into the current\n",
    "    for i in nerEntities:\n",
    "        if type(i) == Tree:\n",
    "            current.append(\" \".join([token for token , pos in i.leaves()]))\n",
    "        else:\n",
    "            #if not , put the current into named_entities\n",
    "            named_entity = \" \".join(current)\n",
    "            #then put the named_entities into teh result\n",
    "            if named_entity not in result:\n",
    "                result.append(named_entity)\n",
    "                current = []\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rais_entities('which companies went bankrupt in month X of year Y?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'CEO of', 'Apple']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rais_entities('who is the CEO of company Apple?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show questions\n",
    "question1 = \"which companies went bankrupt in month X of year Y?\"\n",
    "question2 = \"what affects GDP?\"\n",
    "question3 = \"what percentage of drop or increase is associated with this property?\"\n",
    "question4 = \"who is the CEO of company X?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use compile transfer str to unicode\n",
    "words = re.compile(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'\\w+', re.UNICODE)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user the unicode transform the question\n",
    "question_vec1 = Counter(words.findall(question1))\n",
    "question_vec2 = Counter(words.findall(question2))\n",
    "question_vec3 = Counter(words.findall(question3))\n",
    "question_vec4 = Counter(words.findall(question4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'what': 1, 'affects': 1, 'GDP': 1})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Result of transformation\n",
    "question_vec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify Questions: CEO \"3\", Bankrupt \"0\", GDP \"1\"\n",
    "#calculate Cosine to decide question belone to which question model\n",
    "def classifier_question(question):\n",
    "    question = Counter(words.findall(question))\n",
    "    cosine_array = np.zeros(4)\n",
    "    #####################question1 and question#######################\n",
    "    intersection1 = set(question_vec1.keys())& set(question.keys())\n",
    "    #print (intersection1)\n",
    "    numerator1 =sum([question_vec1[x]*question[x] for x in intersection1])\n",
    "    #print (numerator1)\n",
    "    sum1a = sum([question_vec1[x]**2 for x in question_vec1.keys()])\n",
    "    #print (sum1a)\n",
    "    sum1b = sum([question[x] ** 2 for x in question.keys()])\n",
    "    #print (sum1b)\n",
    "    denominator1 = math.sqrt(sum1a) * math.sqrt(sum1b)\n",
    "    #print (denominator1)\n",
    "    if not denominator1:\n",
    "        cosine_array[0] = 0.0\n",
    "    else:\n",
    "        cosine_array[0] = float(numerator1)/denominator1\n",
    "    #print (cosine_array[0])\n",
    "    #############################################################\n",
    "    ######################question2 and question#######################\n",
    "    intersection2 = set(question_vec2.keys())& set(question.keys())\n",
    "    numerator2 =sum([question_vec2[x]*question[x] for x in intersection2])\n",
    "    \n",
    "    sum2a = sum([question_vec2[x]**2 for x in question_vec2.keys()])\n",
    "    sum2b = sum([question[x] ** 2 for x in question.keys()])\n",
    "    denominator2 = math.sqrt(sum2a) * math.sqrt(sum2b)\n",
    "    if not denominator2:\n",
    "        cosine_array[1] = 0.0\n",
    "    else:\n",
    "        cosine_array[1] = float(numerator2)/denominator2\n",
    "    #############################################################\n",
    "    ######################question3 and question#######################    \n",
    "    intersection3 = set(question_vec3.keys())& set(question.keys())\n",
    "    numerator3 =sum([question_vec3[x]*question[x] for x in intersection3])\n",
    "    \n",
    "    sum3a = sum([question_vec3[x]**2 for x in question_vec3.keys()])\n",
    "    sum3b = sum([question[x] ** 2 for x in question.keys()])\n",
    "    denominator3 = math.sqrt(sum3a) * math.sqrt(sum3b)\n",
    "    if not denominator3:\n",
    "        cosine_array[2] = 0.0\n",
    "    else:\n",
    "        cosine_array[2] = float(numerator3)/denominator3\n",
    "    #############################################################\n",
    "    ######################question4 and question#######################      \n",
    "    intersection4 = set(question_vec4.keys())& set(question.keys())\n",
    "    numerator4 =sum([question_vec4[x]*question[x] for x in intersection4])\n",
    "    \n",
    "    sum4a = sum([question_vec4[x]**2 for x in question_vec4.keys()])\n",
    "    sum4b = sum([question[x] ** 2 for x in question.keys()])\n",
    "    denominator4 = math.sqrt(sum4a) * math.sqrt(sum4b)\n",
    "    if not denominator4:\n",
    "        cosine_array[3] = 0.0\n",
    "    else:\n",
    "        cosine_array[3] = float(numerator4)/denominator4\n",
    "    #show the maximal number's index\n",
    "    max_index = np.argmax(cosine_array)\n",
    "    \n",
    "    return max_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test this define\n",
    "questiontype = classifier_question(\"What percentage of drop or increase is associated with this property?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#questiontype= 2 it means this question belone with question model-3\n",
    "questiontype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the function about find CEO name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_CEO(question):\n",
    "    #Raise entities ，the result like 'CEO OF ***'\n",
    "    nameEnitities = rais_entities(question)\n",
    "    \n",
    "    #Use Elasticsearch to search result\n",
    "    ESsearch = es_articles.search(index='articles_all' , q = nameEnitities , size = 1000)\n",
    "    \n",
    "    #take out the sentence from ESsearch\n",
    "    ES_result = []\n",
    "    for i in np.arange(len(ESsearch['hits']['hits'])):\n",
    "        ES_result.append(ESsearch['hits']['hits'][i]['_source']['body'])\n",
    "        ES_result[i] = nltk.word_tokenize(ES_result[i])\n",
    "        \n",
    "    #word_tokenize the nameEntities \n",
    "    #find the company name from question\n",
    "    tq = nltk.word_tokenize(nameEnitities[0])\n",
    "    if 'of' in tq:\n",
    "        tq.remove('of')\n",
    "    if len(tq) == 1:\n",
    "        companyname = tq[0]\n",
    "    else:\n",
    "        companyname = tq[1]\n",
    "    if len(companyname) > 2:\n",
    "        for i in range(2, len(tq)):\n",
    "            companyname = companyname + ' ' + tq[i]\n",
    "    \n",
    "    #find sentence form ES_result what about company and CEO\n",
    "    about_company = []\n",
    "    for i in np.arange(len(ES_result)):\n",
    "        switch = 1\n",
    "        for j in np.arange(len(tq)):\n",
    "            if tq[j] not in ES_result[i]:\n",
    "                switch = 0\n",
    "        if switch == 1:\n",
    "            about_company.append(ES_result[i])\n",
    "        \n",
    "    #deal with about_company , use rais_ectities get keywords from about_company\n",
    "    #resule_ceo is all about caompany and CEO.\n",
    "    result_ceo = []\n",
    "    for i in np.arange(len(about_company)):\n",
    "        entities_result = rais_entities(about_company[i])\n",
    "        for j in np.arange(len(entities_result)):\n",
    "            if (entities_result[j] != companyname) and (len(nltk.word_tokenize(entities_result[j])))==2:\n",
    "                result_ceo.append(entities_result[j])\n",
    "    \n",
    "    \n",
    "    #If 'companyname' 'CEO' in the same sentence , teh CEO name have large probability in this sentence\n",
    "    #use max(set,key) function find the CEO_name\n",
    "    return max(set(result_ceo),key = result_ceo.count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mark Zuckerberg'"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test this function\n",
    "find_CEO('What is the CEO of Facebook?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jeff Bezos'"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_CEO('What is the CEO of Amazon?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marissa Mayer'"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_CEO(\"Who is the CEO of Yahoo?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the function to find bankruptcy company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Search, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bankruptcy(question):\n",
    "    monthdict = {'January':1, 'February':2, 'March':3, 'April':4,\n",
    "                'May':5, 'June':6, 'July':7, 'August':8,\n",
    "                'September':9 , 'October':10 , 'November':11 , 'December':12}\n",
    "    #word_tokenize the question\n",
    "    tq = nltk.word_tokenize(question)\n",
    "    \n",
    "    #Use dict to find month\n",
    "    month = list(filter(lambda x:x in tq , monthdict))[0]\n",
    "    \n",
    "    # Use RE to find yeas\n",
    "    years = re.findall(r'\\d{4}' , question)\n",
    "    if years:\n",
    "        year = years[0]\n",
    "    else:\n",
    "        return \"Please provide which year\"\n",
    "    \n",
    "    #put the moth and year into the datequrey\n",
    "    datequrey = []\n",
    "    datequrey.append(month)\n",
    "    datequrey.append(years[0])\n",
    "    print (datequrey)\n",
    "    \n",
    "    #Use Elasticsearch to find result about 'moth' and 'yesr'\n",
    "    ESsearch = es_articles.search(index='articles_all' , q = datequrey ,size = 1000)\n",
    "    \n",
    "    #find sentence form Essearch what about month and year\n",
    "    out_hits = ESsearch['hits']['hits']\n",
    "    for_sentence = []\n",
    "    for i in np.arange(len(out_hits)):\n",
    "        sent = out_hits[i]['_source']['body']\n",
    "        \n",
    "        #word_tokenize the sent\n",
    "        ts = nltk.word_tokenize(sent)\n",
    "        \n",
    "        #delete the stop words\n",
    "        ts = [token for token in ts if not token in stop_words]\n",
    "        \n",
    "        #If we want to find which year and month the sentence must have 'month','year' \n",
    "        # and one of the 'key_words = ['bankruptcy','bankrupt','broke']''\n",
    "        if datequrey[0] in ts and datequrey[1] in ts and ('bankruptcy' in ts or 'bankrupt' in ts or 'broke' in ts):\n",
    "            for_sentence.append(sent)\n",
    "            #print (for_sentence)\n",
    "    candidates = []\n",
    "    for i in np.arange(len(for_sentence)):\n",
    "        ne = rais_entities(for_sentence[i])\n",
    "        for j in np.arange(len(ne)):\n",
    "            if ne[j] != '':\n",
    "                candidates.append(ne[j].lower())\n",
    "    #print (candidates)\n",
    "    #use max(set,key) function find the company_name\n",
    "    return max(set(candidates), key = candidates.count)\n",
    "      \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['September', '2008']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lehman brothers'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_bankruptcy(\"Which company went bankrupt in September 2008?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['October', '2014']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'detroit'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_bankruptcy(\"Which company went bankrupt in October 2014?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['October', '2008']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'seeitmarket'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_bankruptcy(\"Which company went bankrupt in October 2008?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the function to find what affect GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affect_GDP(question):\n",
    "    \n",
    "    #Analysis question\n",
    "    tq = nltk.word_tokenize(question)\n",
    "    if '?' in tq:\n",
    "        tq.remove('?')\n",
    "    pos_question = nltk.pos_tag(tq)\n",
    "    keywords = []\n",
    "    for i in range(len(tq)-1,-1,-1):\n",
    "        if pos_question[i][1] != 'TO' and pos_question[i][1] !='IN':\n",
    "            keywords.insert(0,tq[i])\n",
    "        else:\n",
    "            break\n",
    "   \n",
    "    #definr the keywords about affect and GDP\n",
    "    GDPquery = ['GDP','effect','effects','affect','affects']\n",
    "    ESsearch = es_articles.search(index='articles_all' , q = GDPquery ,size=1000)\n",
    "    GDPresult = ESsearch['hits']['hits']\n",
    "    \n",
    "    #raise sentence form ESsearch\n",
    "    candgdp = []\n",
    "    for i in np.arange(len(GDPresult)):\n",
    "        sent = GDPresult[i]['_source']['body']\n",
    "        ts = nltk.word_tokenize(sent)\n",
    "        \n",
    "        #delete stopwords\n",
    "        ts = [token for token in ts if not token in stop_words]\n",
    "        candgdp.append(ts)\n",
    "    pos_taglist = []\n",
    "    \n",
    "    #if one sentence have 'GDP' and one of ('effect','effects','affect','affects')\n",
    "    #raise them and use pos_tag deal with them\n",
    "    for i in range(len(candgdp)):\n",
    "        if 'GDP' in candgdp[i] and ('effect' in candgdp[i] or 'affect' in candgdp[i] or 'effects' in candgdp[i] or 'affects' in candgdp[i]):\n",
    "            pt = nltk.pos_tag(candgdp[i])\n",
    "            pos_taglist.append(pt)\n",
    "    \n",
    "    #raise 'NN' from pos_taglist\n",
    "    NN_list = []\n",
    "    for i in range(len(pos_taglist)):\n",
    "        for j in range(len(pos_taglist[i])):\n",
    "            if 'NN'in pos_taglist[i][j] :\n",
    "                \n",
    "                NN_list.append(pos_taglist[i][j])\n",
    "                #print (pos_taglist[i][j])\n",
    "    \n",
    "    #deal with NN_list , delete symbol\n",
    "    candresult = []\n",
    "    for i in range(len(NN_list)):\n",
    "        candresult.append(str(NN_list[i]).replace('NN' , '').replace('\\'','').replace(',','').replace('(','').replace(')',''))\n",
    "    aaa = []\n",
    "    for i in range(len(candresult)):\n",
    "        \n",
    "        #delete ('effect','effects','affect','affects')\n",
    "        if 'effect' not in candresult[i] and 'affect' not in candresult[i] and 'effects' not in candresult[i] and 'affects' not in candresult[i] and 'growth' not in candresult[i] and '%' not in candresult[i]:\n",
    "            aaa.append(candresult[i])\n",
    "    \n",
    "    \n",
    "    if 'most' in tq:\n",
    "        return (max(set(aaa),key = candresult.count))\n",
    "    else:\n",
    "        return(\"Policy,hurricane,Consumption, consumer spending, government spending, investment, imports, exports, foreign trade,tax\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Policy,Consumption, consumer spending, government spending, investment, imports, exports, foreign trade,tax'"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test this function\n",
    "affect_GDP(\"what the  affects GDP?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'policy '"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affect_GDP(\"what the most affects GDP?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the function to deal with“what percentage of drop or increase is associated with this property?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_percent(question):\n",
    "    #List out factor about GDP\n",
    "    factor = 'Policy,Consumption, consumer spending, government spending, investment, imports, exports, foreign trade,tax'\n",
    "    \n",
    "    #word_tokenize the factor\n",
    "    wt_factor = nltk.word_tokenize(factor.lower())\n",
    "    \n",
    "    #word_tokenize the question\n",
    "    wt_question = nltk.word_tokenize(question)\n",
    "    \n",
    "    #Keywords is the factor what question asked\n",
    "    keywords = []\n",
    "    for i in range(len(wt_factor)):\n",
    "        for j in range(len(wt_question)):\n",
    "            if wt_factor[i] == wt_question[j]:\n",
    "                keywords.append(wt_factor[i])\n",
    "    \n",
    "    #Clean the keywords\n",
    "    if len(keywords) == 3:\n",
    "        keywords = keywords[0]+' '+keywords[1]\n",
    "        \n",
    "    \n",
    "    if keywords != []:\n",
    "        \n",
    "        #Clean keywords again\n",
    "        qkeyword = str(keywords).replace('[','').replace(']','').replace('\\'','').replace(',' , '')\n",
    "        \n",
    "        #make 'q' to use Elasticsearch\n",
    "        #keyword may have these words\n",
    "        keyword = [qkeyword,'GDP','%','percent','percentage','increase','decrease','growth','effect','effects','affect','affects']\n",
    "        \n",
    "        #Use Elasticsearch\n",
    "        ESsearch = es_articles.search(index = 'articles_all' , q = keyword ,size = 1000)\n",
    "        \n",
    "        #raise the sentence from ESsearch\n",
    "        ES_result = []\n",
    "        for i in np.arange(len(ESsearch['hits']['hits'])):\n",
    "            ES_result.append(ESsearch['hits']['hits'][i]['_source']['body'])\n",
    "            ES_result[i] = nltk.word_tokenize(ES_result[i])\n",
    "        \n",
    "        #udeg the keywords from question , len=1 or len=2\n",
    "        candsent = []\n",
    "        wtkey = nltk.word_tokenize(qkeyword)\n",
    "        for i in range(len(ES_result)):\n",
    "            if len(wtkey) == 2:\n",
    "                \n",
    "                if 'GDP' in ES_result[i] and wtkey[0] in ES_result[i] and wtkey[1] in ES_result[i] and ('%' in ES_result[i] or 'percent' in ES_result[i] or 'percentage' in ES_result[i]) and ('adding' in ES_result[i] or 'growth' in ES_result[i]):\n",
    "                    candsent.append(ES_result[i])\n",
    "            if len(wtkey) == 1:\n",
    "                if 'GDP' in ES_result[i] and qkeyword in ES_result[i] and ('%' in ES_result[i] or 'percent' in ES_result[i] or 'percentage' in ES_result[i]):\n",
    "                    candsent.append(ES_result[i])\n",
    "        \n",
    "        #candsent's sentence have keywords from question and percent\n",
    "        \n",
    "        #Use pos_tag get 'CD' from candsent\n",
    "        percent_result = []\n",
    "        for i in range(len(candsent)):\n",
    "            \n",
    "            #一sentence by sentence\n",
    "            postag = nltk.pos_tag(candsent[i])\n",
    "            \n",
    "            \n",
    "            for j in range(len(postag)):\n",
    "                if 'CD' in postag[j]:\n",
    "                    percent_result.append(str(postag[j]).replace('[','').replace(']','').replace('\\'','').replace(',' , '').replace('(','').replace(')','').replace('CD','').replace('2013','').replace('2014',''))\n",
    "        \n",
    "        #return result\n",
    "        return (max(set(percent_result) , key = percent_result.count)+\"percent\")\n",
    "    else :\n",
    "        return (\"Please input the true factor\")\n",
    "    #print (keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.83 percent'"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test this function\n",
    "find_percent(\"what percentage change in GDP results from government spending?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2 percent'"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_percent(\"what percentage change in GDP results from consumer spending?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7 percent'"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_percent(\"what percentage change in GDP results from foreign trade?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function to call above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(question):\n",
    "    question_type = classifier_question(question)\n",
    "    \n",
    "    if question_type == 0:\n",
    "        return find_bankruptcy(question)\n",
    "    if question_type == 1:\n",
    "        return affect_GDP(question)\n",
    "    if question_type == 2:\n",
    "        return find_percent(question)\n",
    "    if question_type == 3:\n",
    "        return find_CEO(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Policy,hurricane,Consumption, consumer spending, government spending, investment, imports, exports, foreign trade,tax'"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"what the  affects GDP?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'policy '"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"what the most  affects GDP?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2 percent'"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"What percentage of drop or increase is associated with this consumer spending?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.83 percent'"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"What percentage of drop or increase is associated with this government spending?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7 percent'"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"What percentage of drop or increase is associated with this foreign trade?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mark Zuckerberg'"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"What is the CEO of Facebook?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marissa Mayer'"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"What is the CEO of Yahoo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jeff Bezos'"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"What is the CEO of Amazon?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['September', '2008']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lehman brothers'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"Which company went bankrupt in September 2008?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['October', '2014']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'detroit'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"Which company went bankrupt in October 2014?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['October', '2008']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'seeitmarket'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"Which company went bankrupt in October 2008?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
